name: Deploy Dev, then Promote to Prod

on:
  push:
    branches: [ dev ]
    paths-ignore:
      - README.md
  pull_request:
    branches: [ dev ]
    paths-ignore:
      - README.md

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  AWS_REGION: eu-west-1
  TERRAFORM_VERSION: 1.6.0
  # Prod-specific toggles (used during promotion)
  USE_EXISTING_DB_SUBNET_GROUP: "true"
  EXISTING_DB_SUBNET_GROUP_NAME: "devops-job-portal-prod-db-subnet-group"
  # Dev-specific toggles (avoid modifying an existing dev DB subnet group in a different VPC)
  USE_EXISTING_DB_SUBNET_GROUP_DEV: "true"
  EXISTING_DB_SUBNET_GROUP_NAME_DEV: "devops-job-portal-dev-db-subnet-group"

jobs:
  terraform-plan:
    name: Terraform Plan (Development)
    runs-on: ubuntu-latest
    # No environment gating for dev to keep pipeline simple
    outputs:
      has_changes: ${{ steps.detect_changes.outputs.has_changes }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
        cache-dependency-path: backend/requirements.txt

    - name: Install Python dependencies
      run: |
        cd backend
        pip install -r requirements.txt -t .

    - name: Package Lambda functions
      run: |
        cd backend
        # After installing deps into ./, bundle code + dependencies per function.
        # Exclude boto3/botocore since they are available in the Lambda runtime and bloat the zip size.
        for f in submit_cv list_applications get_application admin_login; do
          zip -r ../terraform/${f}.zip . \
            -x "boto3/*" "botocore/*" "s3transfer/*" "__pycache__/*" "*.pyc"
        done

        # Stabilize timestamps to avoid hash drift between jobs
        touch -t 202401010000 ../terraform/*.zip

    - name: Upload Lambda Packages
      uses: actions/upload-artifact@v4
      with:
        name: lambda-packages
        path: terraform/*.zip
        retention-days: 1

    - name: Terraform Format
      id: fmt
      run: terraform fmt -check
      working-directory: ./terraform
      continue-on-error: true

    - name: Terraform Init
      id: init
      run: |
        terraform init \
          -backend-config="bucket=terraform-state-devops-job-portal" \
          -backend-config="key=dev/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="dynamodb_table=terraform-locks"
      working-directory: ./terraform

    - name: Cache Terraform providers (dev)
      uses: actions/cache@v4
      with:
        path: terraform/.terraform
        key: ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-${{ hashFiles('terraform/.terraform.lock.hcl') }}
        restore-keys: |
          ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-

    - name: Terraform Workspace
      id: workspace
      run: |
        terraform workspace select dev || terraform workspace new dev
      working-directory: ./terraform

    - name: Terraform Validate
      id: validate
      run: terraform validate -no-color
      working-directory: ./terraform

    - name: Import existing dev resources (best-effort)
      run: |
        set -e
        echo "Importing known pre-existing dev resources to avoid AlreadyExists errors..."
        cd terraform

        # 1) Secrets Manager secret (unconditional import attempt)
        SECRET_NAME="devops-job-portal-dev-admin-credentials"
        terraform state show aws_secretsmanager_secret.admin_credentials >/dev/null 2>&1 || terraform import aws_secretsmanager_secret.admin_credentials "$SECRET_NAME" || true

        # 2) IAM Roles (unconditional import attempts)
        terraform state show aws_iam_role.admin_login_lambda >/dev/null 2>&1 || terraform import aws_iam_role.admin_login_lambda devops-job-portal-dev-admin-login-lambda || true
        terraform state show aws_iam_role.api_gateway_cloudwatch >/dev/null 2>&1 || terraform import aws_iam_role.api_gateway_cloudwatch devops-job-portal-dev-api-gateway-cloudwatch || true
        terraform state show aws_iam_role.lambda >/dev/null 2>&1 || terraform import aws_iam_role.lambda devops-job-portal-dev-lambda-role || true
        terraform state show aws_iam_role.rds_monitoring >/dev/null 2>&1 || terraform import aws_iam_role.rds_monitoring devops-job-portal-dev-rds-monitoring-role || true

        # 3) CloudWatch Log Groups (unconditional import attempts)
        terraform state show aws_cloudwatch_log_group.admin_login >/dev/null 2>&1 || terraform import aws_cloudwatch_log_group.admin_login /aws/lambda/devops-job-portal-dev-admin-login || true
        terraform state show aws_cloudwatch_log_group.submit_cv  >/dev/null 2>&1 || terraform import aws_cloudwatch_log_group.submit_cv  /aws/lambda/devops-job-portal-dev-submit-cv || true
        terraform state show aws_cloudwatch_log_group.list_applications >/dev/null 2>&1 || terraform import aws_cloudwatch_log_group.list_applications /aws/lambda/devops-job-portal-dev-list-applications || true
        terraform state show aws_cloudwatch_log_group.get_application >/dev/null 2>&1 || terraform import aws_cloudwatch_log_group.get_application /aws/lambda/devops-job-portal-dev-get-application || true
        terraform state show aws_cloudwatch_log_group.api_gateway >/dev/null 2>&1 || terraform import aws_cloudwatch_log_group.api_gateway /aws/apigateway/devops-job-portal-dev || true

        # 4) S3 Buckets (unconditional import attempts)
        terraform state show aws_s3_bucket.frontend   >/dev/null 2>&1 || terraform import aws_s3_bucket.frontend   devops-job-portal-dev-frontend || true
        terraform state show aws_s3_bucket.cv_storage >/dev/null 2>&1 || terraform import aws_s3_bucket.cv_storage devops-job-portal-dev-cv-storage || true

        # 5) RDS DB Subnet Group and Parameter Group
        # Using existing DB subnet group in dev; ensure not tracked to avoid cross-VPC modify
        terraform state show aws_db_subnet_group.main >/dev/null 2>&1 && terraform state rm aws_db_subnet_group.main || true
        terraform state show aws_db_subnet_group.main[0] >/dev/null 2>&1 && terraform state rm aws_db_subnet_group.main["0"] || true
        terraform state show aws_db_parameter_group.main >/dev/null 2>&1 || terraform import aws_db_parameter_group.main devops-job-portal-dev-postgres-params || true

        # 6) NAT EIP and NAT Gateway (index 0) via tag discovery to avoid EIP limits
        # Import EIP if one with our Name tag exists
        EIP_ALLOC_ID=$(aws ec2 describe-addresses --filters "Name=tag:Name,Values=devops-job-portal-dev-nat-eip-1" --query 'Addresses[0].AllocationId' --output text 2>/dev/null || echo "None")
        if [ "$EIP_ALLOC_ID" != "None" ] && [ "$EIP_ALLOC_ID" != "null" ]; then
          terraform state show aws_eip.nat[0] >/dev/null 2>&1 || terraform import aws_eip.nat["0"] "$EIP_ALLOC_ID" || true
        fi

        # Import NAT Gateway if one with our Name tag exists
        NAT_ID=$(aws ec2 describe-nat-gateways --filter "Name=tag:Name,Values=devops-job-portal-dev-nat-1" --query 'NatGateways[0].NatGatewayId' --output text 2>/dev/null || echo "None")
        if [ "$NAT_ID" != "None" ] && [ "$NAT_ID" != "null" ]; then
          terraform state show aws_nat_gateway.main[0] >/dev/null 2>&1 || terraform import aws_nat_gateway.main["0"] "$NAT_ID" || true
        fi

        # 7) Lambda functions (unconditional import attempts)
        terraform state show aws_lambda_function.admin_login       >/dev/null 2>&1 || terraform import aws_lambda_function.admin_login       devops-job-portal-dev-admin-login || true
        terraform state show aws_lambda_function.submit_cv         >/dev/null 2>&1 || terraform import aws_lambda_function.submit_cv         devops-job-portal-dev-submit-cv || true
        terraform state show aws_lambda_function.list_applications >/dev/null 2>&1 || terraform import aws_lambda_function.list_applications devops-job-portal-dev-list-applications || true
        terraform state show aws_lambda_function.get_application   >/dev/null 2>&1 || terraform import aws_lambda_function.get_application   devops-job-portal-dev-get-application || true

        # 8) RDS DB Instance (best effort)
        DB_INSTANCE_ID="devops-job-portal-dev-database"
        terraform state show aws_db_instance.main >/dev/null 2>&1 || terraform import aws_db_instance.main "$DB_INSTANCE_ID" || true

      shell: bash

    - name: Terraform Plan (detailed exit code)
      id: detect_changes
      run: |
        set +e
        terraform plan -no-color -detailed-exitcode \
          -var="environment=dev" \
          -var="use_existing_db_subnet_group=${{ env.USE_EXISTING_DB_SUBNET_GROUP_DEV }}" \
          -var="existing_db_subnet_group_name=${{ env.EXISTING_DB_SUBNET_GROUP_NAME_DEV }}" \
          -out=tfplan
        CODE=$?
        echo "exit_code=$CODE"
        if [ "$CODE" -eq 0 ]; then
          echo "has_changes=false" >> $GITHUB_OUTPUT
          exit 0
        elif [ "$CODE" -eq 2 ]; then
          echo "has_changes=true" >> $GITHUB_OUTPUT
          exit 0
        else
          exit 1
        fi
      working-directory: ./terraform

    - name: Upload Plan
      if: steps.detect_changes.outputs.has_changes == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan-dev
        path: terraform/tfplan
        retention-days: 3

    - name: Update Pull Request
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request'
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fmt = "${{ steps.fmt.outcome }}";
          const init = "${{ steps.init.outcome }}";
          const validate = "${{ steps.validate.outcome }}";
          const hasChanges = "${{ steps.detect_changes.outputs.has_changes }}";
          const planSummary = hasChanges === 'true' ? 'changes detected' : 'no changes';
          const output = `#### Terraform Format and Style 🖌\`${fmt}\`
          #### Terraform Initialization ⚙️\`${init}\`
          #### Terraform Validation 🤖\`${validate}\`
          #### Terraform Plan 📖\`${planSummary}\`

          Plan artifact: terraform-plan-dev (if changes were detected)

          *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: output
          })

    - name: Terraform Plan Status
      if: failure()
      run: exit 1

  deploy:
    name: Deploy to Development
    needs: terraform-plan
    runs-on: ubuntu-latest
    # No environment gating for dev to keep pipeline simple
    if: needs.terraform-plan.outputs.has_changes == 'true' && github.ref == 'refs/heads/dev' && github.event_name == 'push'
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
        cache-dependency-path: backend/requirements.txt

    - name: Install Python dependencies
      run: |
        cd backend
        pip install -r requirements.txt -t .

    - name: Download Lambda Packages
      uses: actions/download-artifact@v4
      with:
        name: lambda-packages
        path: terraform/

    - name: Terraform Init
      run: |
        terraform init \
          -backend-config="bucket=terraform-state-devops-job-portal" \
          -backend-config="key=dev/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="dynamodb_table=terraform-locks"
      working-directory: ./terraform

    - name: Cache Terraform providers (dev)
      uses: actions/cache@v4
      with:
        path: terraform/.terraform
        key: ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-${{ hashFiles('terraform/.terraform.lock.hcl') }}
        restore-keys: |
          ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-

    - name: Terraform Workspace
      run: |
        terraform workspace select dev
      working-directory: ./terraform

    - name: Download Plan
      uses: actions/download-artifact@v4
      with:
        name: terraform-plan-dev
        path: terraform/

    - name: Terraform Apply
      run: |
        terraform apply -auto-approve tfplan
      working-directory: ./terraform

    - name: Get Terraform Outputs
      id: terraform-output
      run: |
        set -e
        FRONTEND_BUCKET=$(terraform output -raw frontend_bucket_name)
        API_URL=$(terraform output -raw api_gateway_url)
        # Try to read a website URL output; otherwise build the standard S3 website URL
        if terraform output -raw frontend_website_url >/dev/null 2>&1; then
          FRONTEND_URL=$(terraform output -raw frontend_website_url)
        else
          FRONTEND_URL="http://${FRONTEND_BUCKET}.s3-website-${AWS_REGION}.amazonaws.com"
        fi
        echo "frontend_bucket=${FRONTEND_BUCKET}" >> $GITHUB_OUTPUT
        echo "api_gateway_url=${API_URL}" >> $GITHUB_OUTPUT
        echo "frontend_url=${FRONTEND_URL}" >> $GITHUB_OUTPUT
      working-directory: ./terraform

    - name: Update Frontend Configuration
      run: |
        sed -i "s|https://your-api-gateway-url.execute-api.us-east-1.amazonaws.com/dev|${{ steps.terraform-output.outputs.api_gateway_url }}|g" frontend/js/app.js

    - name: Deploy Frontend to S3
      run: |
        aws s3 sync frontend/ s3://${{ steps.terraform-output.outputs.frontend_bucket }} --delete
        aws s3 cp frontend/index.html s3://${{ steps.terraform-output.outputs.frontend_bucket }}/index.html --cache-control "no-cache"

    - name: Invalidate CloudFront (if exists)
      run: |
        echo "CloudFront invalidation would go here if CDN is configured"
      continue-on-error: true

    - name: Publish Dev URLs
      run: |
        echo "✅ Development deployment successful!" | tee -a $GITHUB_STEP_SUMMARY
        echo "Frontend URL: ${{ steps.terraform-output.outputs.frontend_url }}" | tee -a $GITHUB_STEP_SUMMARY
        echo "API URL: ${{ steps.terraform-output.outputs.api_gateway_url }}" | tee -a $GITHUB_STEP_SUMMARY

  test:
    name: Dev Smoke Tests
    needs: deploy
    runs-on: ubuntu-latest
    if: needs.deploy.result == 'success' && github.ref == 'refs/heads/dev' && github.event_name == 'push'
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Terraform Init (dev)
      
      run: |
        terraform init \
          -backend-config="bucket=terraform-state-devops-job-portal" \
          -backend-config="key=dev/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="dynamodb_table=terraform-locks"
      working-directory: ./terraform

    - name: Cache Terraform providers (dev)
      uses: actions/cache@v4
      with:
        path: terraform/.terraform
        key: ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-${{ hashFiles('terraform/.terraform.lock.hcl') }}
        restore-keys: |
          ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-

    - name: Terraform Workspace (dev)
      run: terraform workspace select dev
      working-directory: ./terraform

    - name: Read Terraform Outputs (dev)
      id: dev-out
      run: |
        echo "frontend_bucket=$(terraform output -raw frontend_bucket_name)" >> $GITHUB_OUTPUT
        echo "api_gateway_url=$(terraform output -raw api_gateway_url)" >> $GITHUB_OUTPUT
        echo "frontend_url=http://$(terraform output -raw frontend_bucket_name).s3-website-${{ env.AWS_REGION }}.amazonaws.com" >> $GITHUB_OUTPUT
      working-directory: ./terraform

    - name: Run basic health checks (dev)
      run: |
        set -e
        API="${{ steps.dev-out.outputs.api_gateway_url }}/applications"
        FE="${{ steps.dev-out.outputs.frontend_url }}"
        echo "Checking API: $API"
        for i in {1..10}; do
          if curl -sSf "$API" >/dev/null; then
            echo "API is healthy"; break
          fi
          echo "Attempt $i/10 failed. Sleeping 10s before retry..."; sleep 10
          if [ $i -eq 10 ]; then echo "API health check failed after retries"; exit 1; fi
        done
        echo "Checking Frontend: $FE"
        for i in {1..10}; do
          if curl -sSf "$FE" >/dev/null; then
            echo "Frontend is healthy"; break
          fi
          echo "Attempt $i/10 failed. Sleeping 10s before retry..."; sleep 10
          if [ $i -eq 10 ]; then echo "Frontend health check failed after retries"; exit 1; fi
        done
        echo "✅ Dev environment looks healthy"

    - name: Dump recent Lambda logs on failure
      if: ${{ failure() }}
      run: |
        echo "Dumping recent Lambda logs for troubleshooting..."
        aws logs tail "/aws/lambda/devops-job-portal-dev-list-applications" --since 30m --format short || true
        aws logs tail "/aws/lambda/devops-job-portal-dev-submit-cv" --since 30m --format short || true
        aws logs tail "/aws/lambda/devops-job-portal-dev-get-application" --since 30m --format short || true

  prod-plan:
    name: Terraform Plan (Production)
    needs: [deploy, test]
    runs-on: ubuntu-latest
    # Gate even the planning behind production environment approval
    environment: production
    if: needs.deploy.result == 'success' && needs.test.result == 'success' && github.ref == 'refs/heads/dev' && github.event_name == 'push'
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Download Lambda Packages
      uses: actions/download-artifact@v4
      with:
        name: lambda-packages
        path: terraform/

    - name: Terraform Init (prod)
      run: |
        terraform init \
          -backend-config="bucket=terraform-state-devops-job-portal" \
          -backend-config="key=prod/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="dynamodb_table=terraform-locks"
      working-directory: ./terraform

    - name: Cache Terraform providers (prod)
      uses: actions/cache@v4
      with:
        path: terraform/.terraform
        key: ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-${{ hashFiles('terraform/.terraform.lock.hcl') }}
        restore-keys: |
          ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-

    - name: Terraform Workspace (prod)
      run: |
        terraform workspace select prod || terraform workspace new prod
      working-directory: ./terraform

    - name: Import Existing DB Instance (prod)
      run: |
        echo "🔍 Ensuring DB instance is in Terraform state before planning..."
        DB_INSTANCE_ID="devops-job-portal-prod-database"

        if terraform state show aws_db_instance.main >/dev/null 2>&1; then
          echo "✅ DB instance already tracked in Terraform state"
          terraform state show aws_db_instance.main | head -20 || true
        else
          echo "ℹ️  DB instance not in state; attempting Terraform import..."
          set +e
          IMPORT_OUTPUT=$(terraform import aws_db_instance.main "$DB_INSTANCE_ID" 2>&1)
          IMPORT_CODE=$?
          set -e
          echo "$IMPORT_OUTPUT" | tail -n +1 | sed 's/^/terraform import: /'

          if [ $IMPORT_CODE -eq 0 ]; then
            echo "✅ DB instance import successful"
          else
            if echo "$IMPORT_OUTPUT" | grep -qiE 'DBInstanceNotFound|not.?found|NoSuchEntity'; then
              echo "ℹ️  DB instance not found in AWS; Terraform will create it if needed"
            else
              echo "❌ Import failed for a non-NotFound reason (likely permissions or conflict)."
              echo "⛔ Aborting to avoid generating a bad plan that will fail during apply."
              exit 1
            fi
          fi

          if terraform state show aws_db_instance.main >/dev/null 2>&1; then
            echo "📋 Post-import verification:"
            terraform state show aws_db_instance.main | head -20 || true
          fi
        fi
      working-directory: ./terraform

      

    - name: Ensure DB subnet group not tracked (prod)
      if: env.USE_EXISTING_DB_SUBNET_GROUP == 'true'
      run: |
        echo "🔧 Using existing DB subnet group; ensuring Terraform state does not manage it..."
        if terraform state show aws_db_subnet_group.main >/dev/null 2>&1; then
          echo "🧹 Removing aws_db_subnet_group.main from state to avoid destroy/create"
          terraform state rm aws_db_subnet_group.main
        else
          echo "✅ DB subnet group not in state (good)"
        fi
      working-directory: ./terraform

    - name: Terraform Validate (prod)
      run: terraform validate -no-color
      working-directory: ./terraform

    - name: Terraform Plan (prod)
      run: |
        terraform plan -no-color \
          -var="environment=prod" \
          -var="db_password=${{ secrets.PROD_DB_PASSWORD }}" \
          -var="use_existing_db_subnet_group=${{ env.USE_EXISTING_DB_SUBNET_GROUP }}" \
          -var="existing_db_subnet_group_name=${{ env.EXISTING_DB_SUBNET_GROUP_NAME }}" \
          -out=tfplan
      working-directory: ./terraform

    - name: Upload Plan (prod)
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan-prod
        path: terraform/tfplan
        retention-days: 5

  prod-deploy:
    name: Deploy to Production (Approval Required)
    needs: prod-plan
    runs-on: ubuntu-latest
    environment: production
    if: needs.prod-plan.result == 'success' && github.ref == 'refs/heads/dev' && github.event_name == 'push'
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Download Lambda Packages
      uses: actions/download-artifact@v4
      with:
        name: lambda-packages
        path: terraform/

    - name: Terraform Init (prod)
      run: |
        terraform init \
          -backend-config="bucket=terraform-state-devops-job-portal" \
          -backend-config="key=prod/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="dynamodb_table=terraform-locks"
      working-directory: ./terraform

    - name: Cache Terraform providers (prod)
      uses: actions/cache@v4
      with:
        path: terraform/.terraform
        key: ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-${{ hashFiles('terraform/.terraform.lock.hcl') }}
        restore-keys: |
          ${{ runner.os }}-tf-${{ env.TERRAFORM_VERSION }}-

    - name: Terraform Workspace (prod)
      run: terraform workspace select prod
      working-directory: ./terraform

    - name: Download Plan (prod)
      uses: actions/download-artifact@v4
      with:
        name: terraform-plan-prod
        path: terraform/

    - name: Terraform Apply (prod)
      run: |
        echo "🚀 Applying Terraform changes to production..."
        terraform apply -auto-approve tfplan
        echo "✅ Terraform deployment completed"
      working-directory: ./terraform

    - name: Get Terraform Outputs (prod)
      id: terraform-output-prod
      run: |
        echo "frontend_bucket=$(terraform output -raw frontend_bucket_name)" >> $GITHUB_OUTPUT
        echo "api_gateway_url=$(terraform output -raw api_gateway_url)" >> $GITHUB_OUTPUT
        echo "frontend_url=$(terraform output -raw frontend_website_url)" >> $GITHUB_OUTPUT
      working-directory: ./terraform

    - name: Update Frontend Configuration (prod)
      run: |
        sed -i "s|https://your-api-gateway-url.execute-api.us-east-1.amazonaws.com/dev|${{ steps.terraform-output-prod.outputs.api_gateway_url }}|g" frontend/js/app.js

    - name: Deploy Frontend to S3 (prod)
      run: |
        aws s3 sync frontend/ s3://${{ steps.terraform-output-prod.outputs.frontend_bucket }} --delete
        aws s3 cp frontend/index.html s3://${{ steps.terraform-output-prod.outputs.frontend_bucket }}/index.html --cache-control "no-cache"

    - name: Production Health Check
      run: |
        echo "🏥 Running production health checks..."
        if curl -f "${{ steps.terraform-output-prod.outputs.api_gateway_url }}/applications" >/dev/null 2>&1; then
          echo "✅ API Gateway is responding"
        else
          echo "⚠️ Frontend health check failed"
        fi
        if curl -f "http://${{ steps.terraform-output-prod.outputs.frontend_url }}" >/dev/null 2>&1; then
          echo "✅ Frontend is accessible"
        else
          echo "⚠️ Frontend health check failed"
        fi
        echo "✅ Health checks completed"
      continue-on-error: true

    - name: Notify production deployment success
      if: success()
      run: |
        echo "🎉 Production deployment successful!" | tee -a $GITHUB_STEP_SUMMARY
        echo "Frontend URL: http://${{ steps.terraform-output-prod.outputs.frontend_url }}" | tee -a $GITHUB_STEP_SUMMARY
        echo "API URL: ${{ steps.terraform-output-prod.outputs.api_gateway_url }}" | tee -a $GITHUB_STEP_SUMMARY
        echo "Deployed by: @${{ github.actor }}" | tee -a $GITHUB_STEP_SUMMARY
        echo "Commit: ${{ github.sha }}" | tee -a $GITHUB_STEP_SUMMARY
